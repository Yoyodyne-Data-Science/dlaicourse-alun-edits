{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/lmoroney/dlaicourse/blob/master/Course%202%20-%20Part%206%20-%20Lesson%203%20-%20Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rX8mhOLljYeM"
   },
   "source": [
    "##### Copyright 2019 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "BZSlp3DAjdYf"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1xJZ5glPPCRz",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\UALBIF\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\UALBIF\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\UALBIF\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\UALBIF\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\UALBIF\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\UALBIF\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\UALBIF\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\UALBIF\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\UALBIF\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\UALBIF\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\UALBIF\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\UALBIF\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1xJZ5glPPCRz"
   },
   "outputs": [],
   "source": [
    "# !wget --no-check-certificate \\\n",
    "#     https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
    "#     -O ./tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1xJZ5glPPCRz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"inception_v3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1 (BatchNo (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization_v1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_1 (Batch (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_v1_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_2 (Batch (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_v1_2[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_3 (Batch (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_v1_3[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_4 (Batch (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_v1_4[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_8 (Batch (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_v1_8[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_6 (Batch (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_9 (Batch (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_v1_6[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_v1_9[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_5 (Batch (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_7 (Batch (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_10 (Batc (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_11 (Batc (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_v1_5[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_v1_7[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_10[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_v1_11[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
      "                                                                 activation_7[0][0]               \n",
      "                                                                 activation_10[0][0]              \n",
      "                                                                 activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_15 (Batc (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_15[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_13 (Batc (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_16 (Batc (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_v1_13[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_16[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_12 (Batc (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_14 (Batc (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_17 (Batc (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_18 (Batc (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_12[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_14[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_17[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_18[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
      "                                                                 activation_14[0][0]              \n",
      "                                                                 activation_17[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_22 (Batc (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_22[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_20 (Batc (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_23 (Batc (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_v1_20[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_23[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_19 (Batc (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_21 (Batc (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_24 (Batc (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_25 (Batc (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_19[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_21[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_24[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_25[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
      "                                                                 activation_21[0][0]              \n",
      "                                                                 activation_24[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_27 (Batc (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_v1_27[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_28 (Batc (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_v1_28[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_26 (Batc (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_29 (Batc (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_v1_26[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_v1_29[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
      "                                                                 activation_29[0][0]              \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_34 (Batc (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_34[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_35 (Batc (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_35[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_31 (Batc (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_36 (Batc (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_31[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_36[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_32 (Batc (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_37 (Batc (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_32[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_v1_37[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_30 (Batc (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_33 (Batc (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_38 (Batc (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_39 (Batc (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_30[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_33[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_38[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_39[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
      "                                                                 activation_33[0][0]              \n",
      "                                                                 activation_38[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_44 (Batc (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_44[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_45 (Batc (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_45[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_41 (Batc (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_46 (Batc (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_41[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_46[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_42 (Batc (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_47 (Batc (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_42[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_47[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_40 (Batc (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_43 (Batc (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_48 (Batc (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_49 (Batc (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_40[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_43[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_48[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_49[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "                                                                 activation_48[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_54 (Batc (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_54[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_55 (Batc (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_55[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_51 (Batc (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_56 (Batc (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_51[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_56[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_52 (Batc (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_57 (Batc (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_52[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_v1_57[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_50 (Batc (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_53 (Batc (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_58 (Batc (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_59 (Batc (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_50[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_53[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_58[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_59[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
      "                                                                 activation_53[0][0]              \n",
      "                                                                 activation_58[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_64 (Batc (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_64[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_65 (Batc (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_65[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_61 (Batc (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_66 (Batc (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_61[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_66[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_62 (Batc (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_67 (Batc (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_62[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_67[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_60 (Batc (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_63 (Batc (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_68 (Batc (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_69 (Batc (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_60[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_63[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_68[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_69[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
      "                                                                 activation_63[0][0]              \n",
      "                                                                 activation_68[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_72 (Batc (None, 7, 7, 192)    576         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_72[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 7, 7, 192)    258048      activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_73 (Batc (None, 7, 7, 192)    576         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_73[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 7, 7, 192)    258048      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_70 (Batc (None, 7, 7, 192)    576         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_74 (Batc (None, 7, 7, 192)    576         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_70[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 7, 7, 192)    0           batch_normalization_v1_74[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 3, 3, 320)    552960      activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 3, 3, 192)    331776      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_71 (Batc (None, 3, 3, 320)    960         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_75 (Batc (None, 3, 3, 192)    576         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 3, 3, 320)    0           batch_normalization_v1_71[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 3, 3, 192)    0           batch_normalization_v1_75[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 3, 3, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 3, 3, 1280)   0           activation_71[0][0]              \n",
      "                                                                 activation_75[0][0]              \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 3, 3, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_80 (Batc (None, 3, 3, 448)    1344        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 3, 3, 448)    0           batch_normalization_v1_80[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 3, 3, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 3, 3, 384)    1548288     activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_77 (Batc (None, 3, 3, 384)    1152        conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_81 (Batc (None, 3, 3, 384)    1152        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_77[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_81[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, 3, 3, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 3, 3, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_78 (Batc (None, 3, 3, 384)    1152        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_79 (Batc (None, 3, 3, 384)    1152        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_82 (Batc (None, 3, 3, 384)    1152        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_83 (Batc (None, 3, 3, 384)    1152        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 3, 3, 192)    245760      average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_76 (Batc (None, 3, 3, 320)    960         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_78[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_79[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_82[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_83[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_84 (Batc (None, 3, 3, 192)    576         conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 3, 3, 320)    0           batch_normalization_v1_76[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 3, 3, 768)    0           activation_78[0][0]              \n",
      "                                                                 activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 3, 3, 768)    0           activation_82[0][0]              \n",
      "                                                                 activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 3, 3, 192)    0           batch_normalization_v1_84[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 3, 3, 2048)   0           activation_76[0][0]              \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate[0][0]                \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 3, 3, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_89 (Batc (None, 3, 3, 448)    1344        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 3, 3, 448)    0           batch_normalization_v1_89[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 3, 3, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 3, 3, 384)    1548288     activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_86 (Batc (None, 3, 3, 384)    1152        conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_90 (Batc (None, 3, 3, 384)    1152        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_86[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_90[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, 3, 3, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 3, 3, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_87 (Batc (None, 3, 3, 384)    1152        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_88 (Batc (None, 3, 3, 384)    1152        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_91 (Batc (None, 3, 3, 384)    1152        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_92 (Batc (None, 3, 3, 384)    1152        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 3, 3, 192)    393216      average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_85 (Batc (None, 3, 3, 320)    960         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_87[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_88[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_91[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 3, 3, 384)    0           batch_normalization_v1_92[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_93 (Batc (None, 3, 3, 192)    576         conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 3, 3, 320)    0           batch_normalization_v1_85[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_87[0][0]              \n",
      "                                                                 activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 3, 3, 768)    0           activation_91[0][0]              \n",
      "                                                                 activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 3, 3, 192)    0           batch_normalization_v1_93[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_85[0][0]              \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 activation_93[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 21,802,784\n",
      "Trainable params: 0\n",
      "Non-trainable params: 21,802,784\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "local_weights_file = './tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "\n",
    "pre_trained_model = InceptionV3(input_shape = (150, 150, 3), \n",
    "                                include_top = False, \n",
    "                                weights = None)\n",
    "\n",
    "pre_trained_model.load_weights(local_weights_file)\n",
    "\n",
    "for layer in pre_trained_model.layers:\n",
    "    layer.trainable = False\n",
    "  \n",
    "pre_trained_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1xJZ5glPPCRz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last layer output shape:  (None, 7, 7, 768)\n"
     ]
    }
   ],
   "source": [
    "last_layer = pre_trained_model.get_layer('mixed7')\n",
    "print('last layer output shape: ', last_layer.output_shape)\n",
    "last_output = last_layer.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BMXb913pbvFg"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "# Flatten the output layer to 1 dimension\n",
    "x = layers.Flatten()(last_output)\n",
    "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "# Add a dropout rate of 0.2\n",
    "x = layers.Dropout(0.2)(x)                  \n",
    "# Add a final sigmoid layer for classification\n",
    "x = layers.Dense  (1, activation='sigmoid')(x)           \n",
    "\n",
    "model = Model( pre_trained_model.input, x) \n",
    "\n",
    "model.compile(optimizer = RMSprop(lr=0.0001), \n",
    "              loss = 'binary_crossentropy', \n",
    "              metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O4s8HckqGlnb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# !wget --no-check-certificate \\\n",
    "#         https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip \\\n",
    "#        -O ./tmp/cats_and_dogs_filtered.zip\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import os\n",
    "# import zipfile\n",
    "\n",
    "# local_zip = '//tmp/cats_and_dogs_filtered.zip'\n",
    "\n",
    "# zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "\n",
    "# zip_ref.extractall('/tmp')\n",
    "# zip_ref.close()\n",
    "\n",
    "# Define our example directories and files\n",
    "base_dir = './tmp/cats_and_dogs_filtered'\n",
    "\n",
    "train_dir = os.path.join( base_dir, 'train')\n",
    "validation_dir = os.path.join( base_dir, 'validation')\n",
    "\n",
    "\n",
    "train_cats_dir = os.path.join(train_dir, 'cats') # Directory with our training cat pictures\n",
    "train_dogs_dir = os.path.join(train_dir, 'dogs') # Directory with our training dog pictures\n",
    "validation_cats_dir = os.path.join(validation_dir, 'cats') # Directory with our validation cat pictures\n",
    "validation_dogs_dir = os.path.join(validation_dir, 'dogs')# Directory with our validation dog pictures\n",
    "\n",
    "train_cat_fnames = os.listdir(train_cats_dir)\n",
    "train_dog_fnames = os.listdir(train_dogs_dir)\n",
    "\n",
    "# Add our data-augmentation parameters to ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255.,\n",
    "                                   rotation_range = 40,\n",
    "                                   width_shift_range = 0.2,\n",
    "                                   height_shift_range = 0.2,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "# Note that the validation data should not be augmented!\n",
    "test_datagen = ImageDataGenerator( rescale = 1.0/255. )\n",
    "\n",
    "# Flow training images in batches of 20 using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                    batch_size = 20,\n",
    "                                                    class_mode = 'binary', \n",
    "                                                    target_size = (150, 150))     \n",
    "\n",
    "# Flow validation images in batches of 20 using test_datagen generator\n",
    "validation_generator =  test_datagen.flow_from_directory( validation_dir,\n",
    "                                                          batch_size  = 20,\n",
    "                                                          class_mode  = 'binary', \n",
    "                                                          target_size = (150, 150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Blhq2MAUeyGA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "100/100 - 127s - loss: 0.5284 - accuracy: 0.7515 - val_loss: 0.2699 - val_accuracy: 0.9130\n",
      "Epoch 2/20\n",
      "100/100 - 125s - loss: 0.3878 - accuracy: 0.8270 - val_loss: 0.1600 - val_accuracy: 0.9580\n",
      "Epoch 3/20\n",
      "100/100 - 141s - loss: 0.3597 - accuracy: 0.8480 - val_loss: 0.2207 - val_accuracy: 0.9480\n",
      "Epoch 4/20\n",
      "100/100 - 146s - loss: 0.3184 - accuracy: 0.8585 - val_loss: 0.2421 - val_accuracy: 0.9540\n",
      "Epoch 5/20\n",
      "100/100 - 148s - loss: 0.3141 - accuracy: 0.8665 - val_loss: 0.3336 - val_accuracy: 0.9440\n",
      "Epoch 6/20\n",
      "100/100 - 143s - loss: 0.3209 - accuracy: 0.8680 - val_loss: 0.4901 - val_accuracy: 0.9230\n",
      "Epoch 7/20\n",
      "100/100 - 142s - loss: 0.2759 - accuracy: 0.8870 - val_loss: 0.3701 - val_accuracy: 0.9450\n",
      "Epoch 8/20\n",
      "100/100 - 149s - loss: 0.2959 - accuracy: 0.8755 - val_loss: 0.3806 - val_accuracy: 0.9490\n",
      "Epoch 9/20\n",
      "100/100 - 141s - loss: 0.3012 - accuracy: 0.8785 - val_loss: 0.4329 - val_accuracy: 0.9450\n",
      "Epoch 10/20\n",
      "100/100 - 157s - loss: 0.2911 - accuracy: 0.8760 - val_loss: 0.3079 - val_accuracy: 0.9610\n",
      "Epoch 11/20\n",
      "100/100 - 147s - loss: 0.2768 - accuracy: 0.8865 - val_loss: 0.4027 - val_accuracy: 0.9480\n",
      "Epoch 12/20\n",
      "100/100 - 141s - loss: 0.2750 - accuracy: 0.8920 - val_loss: 0.3544 - val_accuracy: 0.9550\n",
      "Epoch 13/20\n",
      "100/100 - 140s - loss: 0.2929 - accuracy: 0.8825 - val_loss: 0.3251 - val_accuracy: 0.9560\n",
      "Epoch 14/20\n",
      "100/100 - 159s - loss: 0.2734 - accuracy: 0.8840 - val_loss: 0.3061 - val_accuracy: 0.9630\n",
      "Epoch 15/20\n",
      "100/100 - 159s - loss: 0.2434 - accuracy: 0.9025 - val_loss: 0.3523 - val_accuracy: 0.9540\n",
      "Epoch 16/20\n",
      "100/100 - 142s - loss: 0.2478 - accuracy: 0.9010 - val_loss: 0.4897 - val_accuracy: 0.9490\n",
      "Epoch 17/20\n",
      "100/100 - 140s - loss: 0.2580 - accuracy: 0.9005 - val_loss: 0.3801 - val_accuracy: 0.9570\n",
      "Epoch 18/20\n",
      "100/100 - 140s - loss: 0.2448 - accuracy: 0.9045 - val_loss: 0.6032 - val_accuracy: 0.9390\n",
      "Epoch 19/20\n",
      "100/100 - 138s - loss: 0.2581 - accuracy: 0.9030 - val_loss: 0.6630 - val_accuracy: 0.9380\n",
      "Epoch 20/20\n",
      "100/100 - 145s - loss: 0.2418 - accuracy: 0.8990 - val_loss: 0.5580 - val_accuracy: 0.9470\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "            train_generator,\n",
    "            validation_data = validation_generator,\n",
    "            steps_per_epoch = 100,\n",
    "            epochs = 20,\n",
    "            validation_steps = 50,\n",
    "            verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C2Fp6Se9rKuL"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend(loc=0)\n",
    "#plt.figure()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Course 2 - Part 6 - Lesson 3 - Notebook.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
